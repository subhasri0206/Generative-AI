from transformers import MarianMTModel, MarianTokenizer

class Seq2SeqTranslator:
    def __init__(self, src_lang, tgt_lang): # Changed _init_ to __init__
        self.src_lang = src_lang
        self.tgt_lang = tgt_lang
        self.model_name = f'Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}'
        self.tokenizer = MarianTokenizer.from_pretrained(self.model_name)
        self.model = MarianMTModel.from_pretrained(self.model_name)

    def translate_text(self, text):
        # Tokenize the text
        encoded_text = self.tokenizer(text, return_tensors="pt", padding=True)

        # Generate translation using the model
        translated_tokens = self.model.generate(**encoded_text)

        # Decode the generated tokens to get the translated text
        translated_text = self.tokenizer.decode(translated_tokens[0], skip_special_tokens=True)

        return translated_text

def batch_translate_texts(texts, translator):
    translations = {}
    for text in texts:
        translated_text = translator.translate_text(text)
        translations[text] = translated_text
    return translations

if __name__ == "__main__":
    src_lang = 'en'  # Source language (English)
    tgt_lang = 'es'  # Target language (Spanish)

    translator = Seq2SeqTranslator(src_lang, tgt_lang)

    texts_to_translate = [
        "My",
        "Name",
        "is",
        "Subha"
    ]

    translations = batch_translate_texts(texts_to_translate, translator)

    for original, translated in translations.items():
        print(f"{original} -> {translated}")
